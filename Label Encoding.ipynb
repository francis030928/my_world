{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOdFTe/hWRewac2CnWtT1o0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["steps: Label encoding\n","\n","1. get data\n","\n","2. clean data:\n","    a. check for null values\n","    b. if null value is present, either fill the null or drop depending on the number of information the column has lost\n","    c. treat the null values according to their data type: if string column, fill with mode; if number, fill with mean\n","    d. check if there are still null values in the column because some data are always read only, not unchangeable.\n","    e. change the column to their respective types either using label encoder or manually replacing.\n","    \n","3. analyse the dataset using univarite, bivariate and multivariate analysis.\n","\n","4. check the correlation of the entire dataset, if any two columns are highly correlated, say above 90% then we drop one of the two columns.\n","\n","5. create a copy of a dataset, convert all column in this copied dataset to numbers.\n","\n","6. conduct Feature Selection using varying techniques of selecting most appropriate features. thie can be done using Backward and Forward Recursive Feature Elimination Technique, or other techinques.\n","\n","7. having gotten the optimum number of features needed for your analytics, you split into training and testing set. the training set is used to train the algorithm so it can learn from data, then you test the accuracy of the analytical results with a foreign data (test data).\n","\n","8. creation of model.\n"],"metadata":{"id":"iGUg3brCo_tI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLJD_GIBo9sX"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns"]},{"cell_type":"code","source":["df = pd.read_csv(r'C:\\Users\\HP\\OneDrive\\Documents\\Data_set\\all_perth_310121.csv')\n","df.head()"],"metadata":{"id":"WqZRF4vVpnwP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"1UqMK-f8ptZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe()"],"metadata":{"id":"piuTvuSnp0Ji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isnull().sum().sort_values(ascending = False).head(4)"],"metadata":{"id":"u_5t8V_2p4Rc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fill the null values of the float column with the mean of the column\n","df['NEAREST_SCH_RANK'].fillna(df['NEAREST_SCH_RANK'].mean(), inplace = True)\n","df['NEAREST_SCH_RANK'].isnull().sum()"],"metadata":{"id":"RwdckIypp8hS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fill the null values of the float column with the mean of the column \n","df['BUILD_YEAR'].fillna(df['BUILD_YEAR'].mean(), inplace = True)\n","df['BUILD_YEAR'].isnull().sum()"],"metadata":{"id":"0QMs2aDzp_7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fill the null values of the float column with the mean of the column\n","df['GARAGE'].fillna(df['GARAGE'].mean(), inplace = True)\n","df['GARAGE'].isnull().sum()"],"metadata":{"id":"TTeurNBaqA7I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['NEAREST_STN'].value_counts()"],"metadata":{"id":"ZuFx_QdWqEMO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['NEAREST_STN'].unique()"],"metadata":{"id":"MV-ewievqHfR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['SUBURB'].value_counts()"],"metadata":{"id":"yqf7LkDJqKlT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['SUBURB'].unique()"],"metadata":{"id":"HtRDfPk5qN52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# label encoding\n","from sklearn import preprocessing\n","\n","#label_encoder object knows how to understand word labels\n","label_encoder = preprocessing.LabelEncoder()\n","\n","#encode labels in column 'SUBURB'\n","df['SUBURB']= label_encoder.fit_transform(df['SUBURB'])\n","df.SUBURB"],"metadata":{"id":"JaGOtxtqqRBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ffpmGn6GqXy2"},"execution_count":null,"outputs":[]}]}